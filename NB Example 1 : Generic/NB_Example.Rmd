---
title: "Naive Bayes - An example using R language"
graphics: yes
output: 
  pdf_document: 
    keep_tex: true
---
The main purpose of this document is to educate the reader with the practical aspect of the application of the Naive Bayes (NB) algorithm. In this direction, here we provide the necessary code snippet to show the reader how to apply the NB algorithm in a data classification problem. We use a publicly available dataset and R language for this demonstration. All the important steps of the implementation of the algorithm are explined below.

**The dataset:** In order to implement the above code, we use the well-known Iris dataset (included with R). It consists of four features (measurements), namely sepal length, sepal width, petal length, and petal width for 150 ﬂowers.  The dataset contains information about three types of iris plants: Setosa, Versicolor and Virginica. In the R package, likelihoods in the Naive Bayes formula for numerical features (e.g. measurements) are calculated using probability distributions.

**Machine learning (ML) task:** In this application, we aim to construct an ML model using NB algorithm to identify (classify) the specie of an Irish flower, based on the values of the four features ( sepal length, sepal width, petal length, and petal width ) of a given Irish flower. So, we're tackling a classification task here.

```{r message=FALSE}
set.seed(12345)
data(iris) # Attach the Iris dataset to the R environment
mydata <- iris # Let's rename the dataset as mydata
dim(mydata) # check dimensions of mydata
sapply(mydata, class) # check the data types of each feature
levels(mydata$Species) # check different levels (values) for each class
head(mydata) # have a look at top data points in mydata
summary(mydata) # some descriptive statitics of the data and a summary of class distributions
```

**Creating training and validation datasets:** We’re going to follow the convention of 80/20 samples ratio to partition the dataset to the training and validation sets. We use the createDataPartition function from the caret package for this purpose.

```{r message=FALSE}
#install.packages("caret") #If the caret package is not installed on your system, uncomment this line to install it first
library(caret) #Loading the library
tr_index <- createDataPartition(mydata$Species, p=0.80, list=FALSE) # List of 80% of the rows
trainSet <- mydata[tr_index,] # select 80% of the data for the trainSet
testSet <- mydata[-tr_index,] # Select the remaining 20% of data for testSet
```

**Building a NB classifier:** Now we will train our NB classiﬁer using the above trainSet. For this purpose, we will utilize e1071 package in R. Note that following lines of code will fit the NB model to the datset and will also display the model details. In this case, the 
priori probabilities for all classes are the same. 

```{r message=FALSE}
#install.packages("e1071") #If the e1071 package is not installed on your system, uncomment this line to install it first
library(e1071)
NBclassfier=naiveBayes(Species~., data=trainSet) # Once you call this line, R fits the NB model using trainSet
print(NBclassfier) # Check the newly fitted model to see if everything is OK.
```

**Make predictions:** Now let's apply the above model to assign labels for test cases in testSet. Then we create the confusion matrix, a table that is often used to describe the performance of a classifier.

```{r message=FALSE}
  testPrediction=predict(NBclassfier, newdata=testSet, type="class") # Assign labels for each test case
  confusionMatrix(testPrediction, testSet$Species) # Print confusion matrix 
```

