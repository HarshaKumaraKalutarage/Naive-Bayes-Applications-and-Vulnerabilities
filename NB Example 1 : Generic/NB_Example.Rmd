---
title: "Naive Bayes - An example using R language"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---
The main purpose of this document is to educate the reader with the practical aspect of the application of the Naive Bayes (NB) algorithm. In this direction, here we provide the necessary code snippet to show the reader how to apply the NB algorithm in a data classification problem. We use a publicly available dataset and R language for this demonstration. All the important steps of the implementation of the algorithm are explined below.

**The dataset:** The dataset: In order to implement the NB algorithm, we use the well-known Iris dataset(included with R). 
It consists of five measurements, plant specie, and some characteristics of 150 flowers. The dataset records  
four features of the flower, namely sepal length, sepal width, petal length, and petal width and three 
species of iris plants: Setosa, Versicolor, and Virginica.

**Machine learning (ML) task:** In this application, we aim to construct an ML model using NB algorithm to identify (classify) the specie of an Irish flower, based on the values of the four features ( sepal length, sepal width, petal length, and petal width ) of a given Irish flower.  

```{r}
data(iris) # Attach the Iris dataset to the R environment
mydata <- iris # Let's rename the dataset as mydata
dim(mydata) # check dimensions of mydata
sapply(mydata, class) # check the data types of each feature
levels(mydata$Species) # check different levels (values) for each class
head(mydata) # have a look at top data points in mydata
summary(mydata) # a summary of class distributions
```
**Creating training and validation datasets:** We’re going to construct a 80/20 partitioning for the training and validation sets. We use the createDataPartition function from the caret package for this purpose.
```{r}
#install.packages("caret") #If the caret package is not installed on your system, uncomment this line to install it first
library(caret) #Loading the library
tr_index <- createDataPartition(mydata$Species, p=0.80, list=FALSE) # List of 80% of the rows
trainSet <- mydata[tr_index,] # select 80% of the data for the trainSet
testSet <- mydata[-tr_index,] # Select the remaining 20% of data for testSet
```
**Building a NB classifier:** Now we will train our NB classiﬁer using the above trainSet. For this purpose, we will utilize e1071 package in R. Note the priori probabilities when outputting the following lines of code. We get the same priori probabilities for all classes.

```{r}
#install.packages("e1071") #If the e1071 package is not installed on your system, uncomment this line to install it first
library(e1071)
NBclassfier=naiveBayes(Species~., data=trainSet) # Once you call this line, R fits the NB model using trainSet
print(NBclassfier) # Check the newly fitted model to see if everything is OK.
```

**Make predictions:** Now let's apply the above model to assign labels for test cases in testSet. Then we create the confusion matrix, a table that is often used to describe the performance of a classifier.
```{r}
  testPrediction=predict(NBclassfier, newdata=testSet, type="class") # Assign labels for each test case
  confusionMatrix(testPrediction, testSet$Species) # Print confusion matrix 
```
We can see that the accuracy is 91.3%. It was a small test set, but whether or not that accuracy is sufficient depends on the problem context and is based on many other factors such as the cost of misclassification to the business.
